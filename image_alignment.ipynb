{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image alignment\n",
    "\n",
    "The purpose of this notebook is to resize and align the ppl, xpl, and false-color TIMA images for use in data collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out manual pixel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two lists of matched coordinate pairs\n",
    "\n",
    "#xpl\n",
    "pts1 = np.array([[126, 124], [144, 153], [188, 175], [83, 120], [10,49],\n",
    "                 [138, 71],[52, 168], [28, 182], [124, 25], [79,20]])\n",
    "\n",
    "#ppl\n",
    "pts2 = np.array([[125, 74], [152, 56], [175, 11], [120, 116], [50, 190],\n",
    "                 [71, 61],[168, 147], [182, 170], [25, 77], [19, 120]])\n",
    "# load and view sample image\n",
    "img = cv2.imread('Images/xplimg.png')\n",
    "template = cv2.imread('Images/template.jpg')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(template)\n",
    "# plot dots\n",
    "plt.scatter(pts2[:,0], pts2[:,1], color='r')\n",
    "plt.title('Template Image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img)\n",
    "# plot red dot\n",
    "plt.scatter(pts1[:,0], pts1[:,1],color='r')\n",
    "plt.title('XPL Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(H, mask) = cv2.findHomography(pts1, pts2, method = cv2.RANSAC)\n",
    "\n",
    "# use the homography matrix to align the images\n",
    "(h, w) = template.shape[:2]\n",
    "aligned = cv2.warpPerspective(img, H, (w,h))\n",
    "\n",
    "# resize both the aligned and template images so we can easily \n",
    "# visualize them on the screen\n",
    "aligned = imutils.resize(aligned, width=700)\n",
    "template = imutils.resize(template, width=700)\n",
    "\n",
    "# side-by-side comparison of the output aligned image and the template\n",
    "stacked = np.hstack([aligned, template])\n",
    "\n",
    "# second image alignment visualization will be overlaying the\n",
    "# aligned image on the template to get an idea of how good\n",
    "# the image alignment is\n",
    "\n",
    "overlay = template.copy()\n",
    "output = aligned.copy()\n",
    "cv2.addWeighted(overlay, 0.5, output, 0.5, 0, output)\n",
    "\n",
    "# show the two output inmage alignment visualizations\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Stacked image')\n",
    "plt.imshow(stacked)\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Overlayed image')\n",
    "plt.imshow(output)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop way to georeference both images and manually select keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = Image.open('Images/xpltest.png')\n",
    "template.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xpl pxl location = (412,966)\n",
      "xpl pxl location = (628,1007)\n",
      "xpl pxl location = (562,682)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import imutils\n",
    "import tkinter as tk\n",
    "# import matplot lib like this, otherwise there is some error with tkinter\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# lists to hold linked pixel coordinates\n",
    "ppl_coords = []\n",
    "xpl_coords = []\n",
    "label_coords = []\n",
    "\n",
    "FRAME_WIDTH = 500\n",
    "FRAME_HEIGHT = 800\n",
    "\n",
    "ppl = Image.open('/Users/kacikus/Dropbox/AutomatedMineralogy_Project/Images/ppltest.jpg')\n",
    "xpl = Image.open('/Users/kacikus/Dropbox/AutomatedMineralogy_Project/Images/xpltest.png')\n",
    "labels = Image.open('/Users/kacikus/Dropbox/AutomatedMineralogy_Project/Images/labels.png')\n",
    "\n",
    "# get  dimensions of the img/template photos\n",
    "width_ppl, height_ppl = ppl.size\n",
    "width_xpl, height_xpl = xpl.size\n",
    "width_lab, height_lab = xpl.size\n",
    "\n",
    "# since we are resizing the images to have a height of FRAME_WIDTH px and width relative to that height\n",
    "# we need an x and y scaler to adjust the pixel locations\n",
    "scaler_ppl = height_ppl/800\n",
    "scaler_xpl = height_xpl/800\n",
    "scaler_lab = height_lab/800\n",
    "\n",
    "# gets the pixel locations from ppl imate\n",
    "def getxy_ppl(event):\n",
    "    print(\"ppl pxl location = ({0},{1})\".format(int(event.x*scaler_ppl), int(event.y*scaler_ppl)))\n",
    "    ppl_coords.append([int(event.x*scaler_ppl), int(event.y*scaler_ppl)])\n",
    "    id = canvas1.create_oval(event.x-4, event.y-4, event.x+4, event.y+4, fill='yellow')\n",
    "\n",
    "# gets pixel locations from the xpl image\n",
    "def getxy_xpl(event):\n",
    "    print(\"xpl pxl location = ({0},{1})\".format(int(event.x*scaler_xpl), int(event.y*scaler_xpl)))\n",
    "    xpl_coords.append([int(event.x*scaler_xpl), int(event.y*scaler_xpl)])\n",
    "    id = canvas2.create_oval(event.x-4, event.y-4, event.x+4, event.y+4, fill='yellow')\n",
    "\n",
    "# gets pixel locations from the false color image\n",
    "def getxy_lab(event):\n",
    "    print(\"label pxl location = ({0},{1})\".format(int(event.x*scaler_lab), int(event.y*scaler_lab)))\n",
    "    label_coords.append([int(event.x*scaler_lab), int(event.y*scaler_lab)])\n",
    "    id = canvas3.create_oval(event.x-4, event.y-4, event.x+4, event.y+4, fill='yellow')\n",
    "\n",
    "   \n",
    "# zoom in and out of the image\n",
    "#def zoom(event=None):\n",
    "\n",
    "# root window for the application\n",
    "root = tk.Tk(className='georef window')\n",
    "\n",
    "# assign\n",
    "root.config(cursor=\"draft_small\")\n",
    "\n",
    "# make dimensions of main window fit the two images\n",
    "root.geometry(\"{0}x{1}\".format(FRAME_HEIGHT*3, FRAME_HEIGHT))\n",
    "\n",
    "# create first frame\n",
    "frame1 = tk.Frame(root, width= FRAME_WIDTH, height=FRAME_HEIGHT)\n",
    "frame1.grid(row=0, column=0, padx=0, pady=0)\n",
    "# create second frame\n",
    "frame2 = tk.Frame(root, bg='#c4ffd2', width= FRAME_WIDTH, height=FRAME_HEIGHT)\n",
    "frame2.grid(row=0, column=1, padx=0, pady=0)\n",
    "# create third frame\n",
    "frame3 = tk.Frame(root, bg='pink', width= FRAME_WIDTH, height=FRAME_HEIGHT)\n",
    "frame3.grid(row=0, column=2, padx=0, pady=0)\n",
    "\n",
    "\n",
    "# create canvas for ppl\n",
    "canvas1 = tk.Canvas(frame1, bg='green', width=FRAME_WIDTH, height=FRAME_HEIGHT)\n",
    "canvas1.grid(row=0, column=0, sticky='nesw')\n",
    "# create canvas for xpl\n",
    "canvas2 = tk.Canvas(frame2, bg='blue', width=FRAME_WIDTH, height=FRAME_HEIGHT)\n",
    "canvas2.grid(row=0, column=1, sticky='nesw')\n",
    "# create canvas for labels\n",
    "canvas3 = tk.Canvas(frame3, bg='pink', width=FRAME_WIDTH, height=FRAME_HEIGHT)\n",
    "canvas3.grid(row=0, column=2, sticky='nesw')\n",
    "\n",
    "# create image location resize it (width, height)\n",
    "canvas1.image = ImageTk.PhotoImage(ppl.resize((int(np.ceil(width_ppl/scaler_ppl)), FRAME_HEIGHT), Image.ANTIALIAS))\n",
    "canvas1.create_image(0, 0, image=canvas1.image, anchor='nw')\n",
    "\n",
    "canvas2.image = ImageTk.PhotoImage(xpl.resize((int(np.ceil(width_xpl/scaler_xpl)), FRAME_HEIGHT), Image.ANTIALIAS))\n",
    "canvas2.create_image(0, 1, image=canvas2.image, anchor='nw')\n",
    "\n",
    "canvas3.image = ImageTk.PhotoImage(labels.resize((int(np.ceil(width_xpl/scaler_lab)), FRAME_HEIGHT), Image.ANTIALIAS))\n",
    "canvas3.create_image(0, 2, image=canvas3.image, anchor='nw')\n",
    "\n",
    "canvas1.bind('<Button-1>', getxy_ppl)\n",
    "canvas2.bind('<Button-1>', getxy_xpl)\n",
    "canvas3.bind('<Button-1>', getxy_lab)\n",
    "\n",
    "\n",
    "# runs the application \n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "https://www.programmersought.com/article/38705290853/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2\n",
    "The above method did not work very well and warped the image quite a bit.\n",
    "\n",
    "I need to:\n",
    "1. Transform an image to fit perfectly on top on another image\n",
    "2. crop so they have the same pixel positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/ppltest.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((25,25), np.float32)/625\n",
    "avg = cv2.filter2D(img, -1, kernel)\n",
    "blur = cv2.GaussianBlur(img, (25,25),0)\n",
    "\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.subplot(131),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132),plt.imshow(dst),plt.title('Averaging')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133),plt.imshow(blur),plt.title('Gaussian Blur')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/image.jpg')\n",
    "edges = cv2.Canny(img, 100, 100)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/xplimg.png')\n",
    "edges = cv2.Canny(img, 50, 2)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare image matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open images\n",
    "# transformed ppl image\n",
    "#img = cv2.imread('Images/image.jpg')\n",
    "\n",
    "# larger ppl image\n",
    "#img = cv2.imread('Images/larger_img.jpg')\n",
    "\n",
    "# transformed xpl image\n",
    "img = cv2.imread('Images/xplimg.png')\n",
    "imgGray = cv2.Canny(img, 50, 2)\n",
    "\n",
    "# original ppl image\n",
    "template = cv2.imread('Images/template.jpg')\n",
    "templateGray = cv2.Canny(template, 100, 100)\n",
    "\n",
    "'''Uncomment when you arent using edges'''\n",
    "# img = cv2.imread('smileyface.jpeg')\n",
    "# template = cv2.imread('template.jpeg')\n",
    "\n",
    "# convert to grayscale\n",
    "#imageGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#templateGray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "height, width = templateGray.shape\n",
    "\n",
    "# use ORB to detect keypoints and extract (binary) \n",
    "# local invariant features\n",
    "orb = cv2.ORB_create(500)\n",
    "kp1, d1 = orb.detectAndCompute(imageGray, None)\n",
    "kp2, d2 = orb.detectAndCompute(templateGray, None)\n",
    "\n",
    "# match features\n",
    "method = cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n",
    "matcher = cv2.DescriptorMatcher_create(method)\n",
    "matches = matcher.match(d1, d2, None)\n",
    "\n",
    "# sort matches by their distance (smaller distance,\n",
    "# means more similar features)\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "no_of_matches = len(matches)\n",
    "\n",
    "# keep only the top matches\n",
    "keep = int(len(matches) * 0.05)\n",
    "matches = matches[:keep]\n",
    "\n",
    "# check to see if we should visualize the matched keypoints\n",
    "matchedVis = cv2.drawMatches(img, kp1, template, kp2, matches, None)\n",
    "matchedVis = imutils.resize(matchedVis, width = 1000)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(matchedVis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate memory for the keypoints (x, y)-coordinates from the\n",
    "# top matches -- we'll use these coordinates to compute homography matrix\n",
    "pts1 = np.zeros((len(matches), 2), dtype='float')\n",
    "pts2 = np.zeros((len(matches), 2), dtype='float')\n",
    "\n",
    "# loop over the top matches\n",
    "for (i, m) in enumerate(matches):\n",
    "    # indicate that the two keypoints int he respective images\n",
    "    # map to each other\n",
    "    pts1[i] = kp1[m.queryIdx].pt\n",
    "    pts2[i] = kp2[m.trainIdx].pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our organized pairs of keypoint matches, now we are ready to align the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute homography matrix between two sets of matched points\n",
    "(H, mask) = cv2.findHomography(pts1, pts2, method = cv2.RANSAC)\n",
    "\n",
    "# use the homography matrix to align the images\n",
    "(h, w) = template.shape[:2]\n",
    "aligned = cv2.warpPerspective(img, H, (w,h))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "# plot original (left) and template (right)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Original (left); template (right)')\n",
    "plt.imshow(matchedVis)\n",
    "# plot the newly aligned image\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Aligned image')\n",
    "plt.imshow(aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare both the newly aligned image and the old image stacked on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize both the aligned and template images so we can easily \n",
    "# visualize them on the screen\n",
    "aligned = imutils.resize(aligned, width=700)\n",
    "template = imutils.resize(template, width=700)\n",
    "\n",
    "# side-by-side comparison of the output aligned image and the template\n",
    "stacked = np.hstack([aligned, template])\n",
    "\n",
    "# second image alignment visualization will be overlaying the\n",
    "# aligned image on the template to get an idea of how good\n",
    "# the image alignment is\n",
    "\n",
    "overlay = template.copy()\n",
    "output = aligned.copy()\n",
    "cv2.addWeighted(overlay, 0.5, output, 0.5, 0, output)\n",
    "\n",
    "# show the two output inmage alignment visualizations\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Stacked image')\n",
    "plt.imshow(stacked)\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Overlayed image')\n",
    "plt.imshow(output)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://www.geeksforgeeks.org/image-registration-using-opencv-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
